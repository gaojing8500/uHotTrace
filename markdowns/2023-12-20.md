## 2023-12-20 Github Trending

### 
* [jmorganca / ollama](https://github.com/jmorganca/ollama): Get up and running with Llama 2 and other large language models locally ***Star:25451 Fork:1534 Today stars:729***
 gpt_summary: Ollama是一个强大的语言模型，可以在本地运行。它支持多种操作系统，包括macOS、Windows和Linux。你可以通过下载安装包或使用curl命令来安装Ollama。此外，Ollama还提供了一系列开源模型供用户下载和使用。

如果你想自定义模型，可以从GGUF、PyTorch或Safetensors导入已有的模型，并通过创建Modelfile文件进行配置。同时，你还可以为Ollama库中的模型设置自定义提示。

除了命令行界面外，Ollama还提供了REST API接口以及与其他应用程序和工具的集成方式。例如，在Web和桌面应用程序中集成Bionic GPT、HTML UI等；在终端中使用oterm或Emacs客户端；在数据库中使用MindsDB等。

总之，Ollama是一个功能强大且灵活可扩展的语言模型框架，在各种场景下都能发挥作用，并且有着广泛的社区支持和整合方案。***
* [facebookresearch / llama-recipes](https://github.com/facebookresearch/llama-recipes): Examples and recipes for Llama 2 model ***Star:5736 Fork:787 Today stars:108***
 gpt_summary: Llama 2是一个新的技术，可以进行微调和推理。它提供了一系列示例、演示应用程序和配方，以帮助用户快速入门。您可以使用这些示例来进行域适应的微调，并运行针对微调模型的推理。此外，还提供了一些演示应用程序，展示了如何在本地、云端或本地部署中使用Llama 2，并与其他生态系统解决方案集成。

为了帮助开发人员处理潜在风险，我们创建了《负责任使用指南》。该指南详细介绍了如何下载模型以及如何安装和使用Llama-recipes。

如果您想要开始快速入门，请查看"Llama 2 Jupyter Notebook"部分，在其中有关于如何在文本摘要任务上对Llama 2模型进行微调的步骤说明。

如果您想要安装Llama-recipes，请按照给出的pip命令进行安装。

如果您需要更多深入信息，请查看单个GPU微调、多个GPU微调等部分。

另外，请注意Llama 2是一项具有潜在风险的新技术，在使用时需要谨慎，并遵循《可接受使用政策》。***
